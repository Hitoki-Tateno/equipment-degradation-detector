# 異常スコアの偽陽性調査

**日付**: 2026-02-20
**ステータス**: 検討中

## 現象

ベースライン付近（work_time ~10）の明らかに正常な点が赤（異常）と表示される。
感度スライダーを中程度に設定しても、全体の約50%が異常扱いになる。

## 調査結果

### SQLite ストアの実データ

anomaly_results テーブルの全364件を直接確認。

**基本統計:**
- 最小スコア: 0.4008 / 最大: 0.7504 / 平均: 0.5161
- **90.1% が 0.40〜0.60 に集中**（ダイナミックレンジが極めて狭い）

**スコアと work_time の相関:**

| スコア帯 | 件数 | 平均 work_time | 備考 |
|----------|------|--------------|------|
| < 0.45（正常） | 56 | 10.15 | |
| 0.45-0.50 | 111 | 9.98 | |
| 0.50-0.55 | 60 | 10.04 | |
| 0.55-0.60 | 101 | 11.52 | |
| 0.60-0.65 | 21 | 13.40 | |
| **>= 0.65（高スコア）** | **15** | **9.59** | **正常値なのに最高スコア** |

最高スコア 0.7504 の work_time は 8.80（正常値）。
一方、work_time 23.7（明らかな異常）のスコアは 0.60-0.65 程度。

### 原因の切り分け

| レイヤー | 問題 | 深刻度 |
|---------|------|--------|
| **バックエンド（分析層）** | 1D Isolation Forest が双方向検知 → 低 work_time にも高スコア付与 | **主原因** |
| **バックエンド（分析層）** | スコアのダイナミックレンジが狭すぎる（0.40-0.75） | **主原因** |
| **バックエンド（分析層）** | sensitivity パラメータが未使用（contamination="auto" 固定） | 設計漏れ |
| **フロントエンド** | 相対閾値計算が狭いスコアレンジを増幅 | 副次的 |
| **フロントエンド** | 色分けロジック自体（`score > threshold`） | 問題なし |

**結論: フロントエンドは「悪いデータに対して正直に動いている」状態。修正すべきはバックエンドの分析層。**

## 根本原因の詳細

### 1. 1D Isolation Forest の構造的限界

現在の特徴量は生の work_time のみ（1次元）。
Isolation Forest の異常スコアは `s(x,n) = 2^{-E(h(x))/c(n)}` で定義され、
ベースラインの work_time がほぼ全部 ~10 に集中している場合、
どの点も孤立させるのに似たような分割回数が必要になり、スコアが 0.5 付近に集中する。

### 2. 双方向検知

Isolation Forest は「ベースラインからの逸脱」を両方向で検知する。
work_time=8.8（低い）も work_time=20（高い）も同様に外れ値と判定。
劣化検知では高い方だけが問題なのに、低い方にも高スコアがつく。

### 3. フロントエンドの閾値計算

```javascript
threshold = max - sensitivity × (max - min)
```

カテゴリ135（スコア範囲 0.4008〜0.6297、幅 = 0.229）の場合:
- 感度 0.6: threshold = 0.6297 - 0.6 × 0.229 = 0.492
- → スコア 0.50 の正常な点も赤になる（全体の約50%が赤）

## 改善案: 特徴量の多次元化

### 現行アーキテクチャで使える特徴量

現在の `FeatureBuilder.build(work_times)` は時系列順の work_time を受け取り `(n, d)` を返す設計。

| # | 特徴量 | 算出方法 | 狙い |
|---|--------|---------|------|
| 1 | **生 work_time** | そのまま | 現行。絶対値の異常 |
| 2 | **前回差分 (Δ)** | `wt[i] - wt[i-1]` | 急激な変化（突発異常） |
| 3 | **移動平均 (MA)** | 直近 k 件の平均 | ノイズ除去、持続的な上昇の検出 |
| 4 | **移動標準偏差** | 直近 k 件の std | ばらつき増大 = 劣化の前兆 |
| 5 | **累積偏差 (CUSUM)** | `Σ(wt[i] - series_mean)` | 緩やかなドリフトの蓄積検出 |
| 6 | **指数移動平均 (EWMA)** | 指数重み付き平均 | 直近の変化に敏感 |
| 7 | **ローカル最大値比** | `wt[i] / max(wt[i-k:i])` | 直近ウィンドウ内でのピーク度合い |

### アーキテクチャ変更が必要な特徴量

`FeatureBuilder` に `fit(baseline)` → `transform(all)` の2段階 API が必要。

| # | 特徴量 | 算出方法 | 狙い |
|---|--------|---------|------|
| 8 | **ベースライン Z-score** | `(wt - bl_mean) / bl_std` | ベースラインからの乖離度。最も直感的 |
| 9 | **ベースライン比率** | `wt / bl_mean` | 1.0 = 正常、1.2 = 2割増 |
| 10 | **ベースライン偏差の CUSUM** | `Σ(wt[i] - bl_mean)` | ベースライン基準でのドリフト |

### なぜ多次元化で双方向問題が緩和されるか

例: 生 work_time + 移動平均 の 2D にした場合

- 生値が高い **かつ** 移動平均も高い → 持続的な劣化（両方向で外れ値 → 高スコア）
- 生値が低い **かつ** 移動平均は普通 → たまたま低いだけ（1方向だけ → スコアが上がりにくい）

### 推奨の優先順位

```
[最小変更]  1 + 2 + 3  (生値 + 差分 + 移動平均 → 3D)
    |       FeatureBuilder の実装差し替えだけで済む
    |       双方向問題がかなり緩和される
    v
[中程度]    上記 + 4 (移動標準偏差 → 4D)
    |       ばらつき増大も検知できる
    v
[要IF変更]  8 (Z-score) を軸にした設計
            最も理想的だがインターフェース変更が伴う
```

## 関連ファイル

- `backend/analysis/anomaly.py` — Isolation Forest のスコア算出
- `backend/analysis/engine.py` — 分析エンジン（特徴量構築 → 学習 → スコア保存）
- `backend/analysis/feature.py` — FeatureBuilder 実装（現在は生 work_time のみ）
- `backend/interfaces/feature.py` — FeatureBuilder 抽象クラス
- `frontend/src/components/WorkTimePlot.jsx` — 閾値計算・色分けロジック

## 関連 Issue

- #64 — anomaly_score を原論文準拠の 0〜1 スケールに修正（完了）
- #63 — フロントエンド閾値計算ロジックの修正（完了）
